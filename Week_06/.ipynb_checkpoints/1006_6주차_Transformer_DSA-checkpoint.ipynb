{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b83c6d7-a6a6-401f-98b1-f133ad1489fb",
   "metadata": {},
   "source": [
    "# 6주차 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed76ad-fa26-4d18-9e33-292b8dc62947",
   "metadata": {},
   "source": [
    "1. DSA data를 불러와서\n",
    "2. 순환 데이터 변형 (Split Sequence)\n",
    "3. Transformer모델로 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76567ea4-cd87-4524-aa80-5bf00dd93fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Choij\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f57e32-7575-4ca5-a0f2-54667f8295f8",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8229101-a9ad-4380-a4a0-0abff5c5e64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Project/DeepLearning/Data/DSA_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b709a1-5e64-47a7-b294-ff89aeb86263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps, n_features):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # 시퀀스의 끝점 계산\n",
    "        end_ix = i + n_steps\n",
    "        # 데이터 범위를 넘어서면 중단\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # 입력 시퀀스는 n_steps 동안의 데이터 (마지막 레이블 제외)\n",
    "        seq_x = sequences[i:end_ix, :n_features]\n",
    "        # 출력은 end_ix 시점에서 30개의 레이블만 가져옴\n",
    "        seq_y = sequences[end_ix-1, n_features:]  # 특정 시점에서 한 번에 30개의 레이블만 가져오기\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6403aef5-8589-4bfa-a7aa-0b788112721b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>6.267229e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>7.403458e-07</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802523e-07</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>5.398837e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.787533e-07</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "0     7.975714      8.1605      7.6823    0.014395    0.119981    -0.023319   \n",
       "1     7.978250      8.1763      7.8472    0.007551    0.086896     0.552416   \n",
       "2     7.970894      8.0860      7.8470    0.003092    0.055603     0.100538   \n",
       "3     7.938412      8.1083      7.6901    0.003763    0.061343    -0.231914   \n",
       "4     7.908930      8.1305      7.8322    0.001741    0.041731     2.042285   \n",
       "\n",
       "   T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...   LL_ymag_var  \\\n",
       "0     1.083150      1.1832     0.99744    0.002208  ...  6.267229e-07   \n",
       "1     1.140865      1.2129     1.05810    0.000784  ...  7.403458e-07   \n",
       "2     1.140962      1.2128     1.07960    0.000508  ...  5.802523e-07   \n",
       "3     1.165260      1.3170     1.07870    0.002173  ...  5.398837e-07   \n",
       "4     1.187504      1.2574     1.09450    0.000662  ...  6.787533e-07   \n",
       "\n",
       "   LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0     0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1     0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2     0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3     0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4     0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "\n",
       "    LL_zmag_var  LL_zmag_std  LL_zmag_skew  activity  \n",
       "0  6.778722e-07     0.000823      0.036729   sitting  \n",
       "1  7.032302e-07     0.000839      0.347471   sitting  \n",
       "2  6.268222e-07     0.000792      0.045579   sitting  \n",
       "3  8.011245e-07     0.000895      0.240690   sitting  \n",
       "4  6.853423e-07     0.000828      0.258429   sitting  \n",
       "\n",
       "[5 rows x 271 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.drop('people', axis=1)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b295fc-3370-45ac-b194-1bf98f922252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>6.267229e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>7.403458e-07</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802523e-07</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>5.398837e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.787533e-07</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "0     7.975714      8.1605      7.6823    0.014395    0.119981    -0.023319   \n",
       "1     7.978250      8.1763      7.8472    0.007551    0.086896     0.552416   \n",
       "2     7.970894      8.0860      7.8470    0.003092    0.055603     0.100538   \n",
       "3     7.938412      8.1083      7.6901    0.003763    0.061343    -0.231914   \n",
       "4     7.908930      8.1305      7.8322    0.001741    0.041731     2.042285   \n",
       "\n",
       "   T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...   LL_ymag_var  \\\n",
       "0     1.083150      1.1832     0.99744    0.002208  ...  6.267229e-07   \n",
       "1     1.140865      1.2129     1.05810    0.000784  ...  7.403458e-07   \n",
       "2     1.140962      1.2128     1.07960    0.000508  ...  5.802523e-07   \n",
       "3     1.165260      1.3170     1.07870    0.002173  ...  5.398837e-07   \n",
       "4     1.187504      1.2574     1.09450    0.000662  ...  6.787533e-07   \n",
       "\n",
       "   LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0     0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1     0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2     0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3     0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4     0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "\n",
       "    LL_zmag_var  LL_zmag_std  LL_zmag_skew  activity  \n",
       "0  6.778722e-07     0.000823      0.036729        12  \n",
       "1  7.032302e-07     0.000839      0.347471        12  \n",
       "2  6.268222e-07     0.000792      0.045579        12  \n",
       "3  8.011245e-07     0.000895      0.240690        12  \n",
       "4  6.853423e-07     0.000828      0.258429        12  \n",
       "\n",
       "[5 rows x 271 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 'label' 컬럼을 숫자로 변환\n",
    "df_filtered['activity'] = label_encoder.fit_transform(df_filtered['activity'])\n",
    "\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f8046-755a-4cf8-9187-f3097c821fb8",
   "metadata": {},
   "source": [
    "## StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1749d1b-925c-4ac9-9040-b35b6c4287c8",
   "metadata": {},
   "source": [
    "각 피쳐의 값 범위가 매우 다르기 때문에 StandardScaler를 통해 스케일을 좁혀보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2672ad4d-3a76-483d-8707-387c4570895d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055870</td>\n",
       "      <td>-0.546828</td>\n",
       "      <td>0.725530</td>\n",
       "      <td>-0.393761</td>\n",
       "      <td>-0.680020</td>\n",
       "      <td>-0.428085</td>\n",
       "      <td>0.860379</td>\n",
       "      <td>-0.148110</td>\n",
       "      <td>1.180617</td>\n",
       "      <td>-0.523874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763476</td>\n",
       "      <td>-1.258551</td>\n",
       "      <td>0.441264</td>\n",
       "      <td>-0.350861</td>\n",
       "      <td>-0.623732</td>\n",
       "      <td>-0.017723</td>\n",
       "      <td>-0.400560</td>\n",
       "      <td>-0.913563</td>\n",
       "      <td>0.204309</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056545</td>\n",
       "      <td>-0.545491</td>\n",
       "      <td>0.754858</td>\n",
       "      <td>-0.393913</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>0.321260</td>\n",
       "      <td>0.886595</td>\n",
       "      <td>-0.141000</td>\n",
       "      <td>1.195850</td>\n",
       "      <td>-0.524238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763471</td>\n",
       "      <td>-1.257727</td>\n",
       "      <td>-0.439297</td>\n",
       "      <td>-0.351291</td>\n",
       "      <td>-0.623682</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>-0.400558</td>\n",
       "      <td>-0.913325</td>\n",
       "      <td>0.705828</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054587</td>\n",
       "      <td>-0.553129</td>\n",
       "      <td>0.754823</td>\n",
       "      <td>-0.394011</td>\n",
       "      <td>-0.698774</td>\n",
       "      <td>-0.266880</td>\n",
       "      <td>0.886639</td>\n",
       "      <td>-0.141024</td>\n",
       "      <td>1.201248</td>\n",
       "      <td>-0.524308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763478</td>\n",
       "      <td>-1.258909</td>\n",
       "      <td>-0.149907</td>\n",
       "      <td>-0.350716</td>\n",
       "      <td>-0.623032</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>-0.400562</td>\n",
       "      <td>-0.914056</td>\n",
       "      <td>0.218593</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045943</td>\n",
       "      <td>-0.551243</td>\n",
       "      <td>0.726917</td>\n",
       "      <td>-0.393997</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.699580</td>\n",
       "      <td>0.897675</td>\n",
       "      <td>-0.116077</td>\n",
       "      <td>1.201022</td>\n",
       "      <td>-0.523883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763479</td>\n",
       "      <td>-1.259232</td>\n",
       "      <td>0.145985</td>\n",
       "      <td>-0.348852</td>\n",
       "      <td>-0.620142</td>\n",
       "      <td>-0.015135</td>\n",
       "      <td>-0.400553</td>\n",
       "      <td>-0.912443</td>\n",
       "      <td>0.533490</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038098</td>\n",
       "      <td>-0.549365</td>\n",
       "      <td>0.752191</td>\n",
       "      <td>-0.394041</td>\n",
       "      <td>-0.702816</td>\n",
       "      <td>2.260389</td>\n",
       "      <td>0.907779</td>\n",
       "      <td>-0.130346</td>\n",
       "      <td>1.204990</td>\n",
       "      <td>-0.524269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763474</td>\n",
       "      <td>-1.258165</td>\n",
       "      <td>-0.176094</td>\n",
       "      <td>-0.347060</td>\n",
       "      <td>-0.619151</td>\n",
       "      <td>-0.013759</td>\n",
       "      <td>-0.400559</td>\n",
       "      <td>-0.913492</td>\n",
       "      <td>0.562119</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "0     0.055870   -0.546828    0.725530   -0.393761   -0.680020    -0.428085   \n",
       "1     0.056545   -0.545491    0.754858   -0.393913   -0.689658     0.321260   \n",
       "2     0.054587   -0.553129    0.754823   -0.394011   -0.698774    -0.266880   \n",
       "3     0.045943   -0.551243    0.726917   -0.393997   -0.697102    -0.699580   \n",
       "4     0.038098   -0.549365    0.752191   -0.394041   -0.702816     2.260389   \n",
       "\n",
       "   T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  LL_ymag_var  \\\n",
       "0     0.860379   -0.148110    1.180617   -0.523874  ...    -0.763476   \n",
       "1     0.886595   -0.141000    1.195850   -0.524238  ...    -0.763471   \n",
       "2     0.886639   -0.141024    1.201248   -0.524308  ...    -0.763478   \n",
       "3     0.897675   -0.116077    1.201022   -0.523883  ...    -0.763479   \n",
       "4     0.907779   -0.130346    1.204990   -0.524269  ...    -0.763474   \n",
       "\n",
       "   LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0    -1.258551      0.441264     -0.350861    -0.623732    -0.017723   \n",
       "1    -1.257727     -0.439297     -0.351291    -0.623682    -0.018691   \n",
       "2    -1.258909     -0.149907     -0.350716    -0.623032    -0.017234   \n",
       "3    -1.259232      0.145985     -0.348852    -0.620142    -0.015135   \n",
       "4    -1.258165     -0.176094     -0.347060    -0.619151    -0.013759   \n",
       "\n",
       "   LL_zmag_var  LL_zmag_std  LL_zmag_skew  activity  \n",
       "0    -0.400560    -0.913563      0.204309        12  \n",
       "1    -0.400558    -0.913325      0.705828        12  \n",
       "2    -0.400562    -0.914056      0.218593        12  \n",
       "3    -0.400553    -0.912443      0.533490        12  \n",
       "4    -0.400559    -0.913492      0.562119        12  \n",
       "\n",
       "[5 rows x 271 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 열 이름의 접두사/접미사를 사용하여 필터링\n",
    "prefixes = ['T_', 'RA_', 'LA_', 'RL_', 'LL_']  # 원하는 접두사 리스트\n",
    "columns_to_scale = df_filtered.columns[df_filtered.columns.str.startswith(tuple(prefixes))]\n",
    "\n",
    "# 선택한 열을 스케일링\n",
    "df_filtered[columns_to_scale] = scaler.fit_transform(df_filtered[columns_to_scale])\n",
    "\n",
    "# 스케일링 후 데이터 확인\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5562d5ce-c74d-44ed-b6a8-fa145afa0755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    480\n",
       "18    480\n",
       "6     480\n",
       "10    480\n",
       "4     480\n",
       "3     480\n",
       "2     480\n",
       "15    480\n",
       "11    480\n",
       "17    480\n",
       "13    480\n",
       "16    480\n",
       "9     480\n",
       "14    480\n",
       "5     480\n",
       "0     480\n",
       "8     480\n",
       "7     480\n",
       "1     480\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fac0362-c0f9-4c77-b1cc-85a83fc2f83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_min</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055870</td>\n",
       "      <td>-0.546828</td>\n",
       "      <td>0.725530</td>\n",
       "      <td>-0.393761</td>\n",
       "      <td>-0.680020</td>\n",
       "      <td>-0.428085</td>\n",
       "      <td>0.860379</td>\n",
       "      <td>-0.148110</td>\n",
       "      <td>1.180617</td>\n",
       "      <td>-0.523874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519750</td>\n",
       "      <td>-0.763476</td>\n",
       "      <td>-1.258551</td>\n",
       "      <td>0.441264</td>\n",
       "      <td>-0.350861</td>\n",
       "      <td>-0.623732</td>\n",
       "      <td>-0.017723</td>\n",
       "      <td>-0.400560</td>\n",
       "      <td>-0.913563</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056545</td>\n",
       "      <td>-0.545491</td>\n",
       "      <td>0.754858</td>\n",
       "      <td>-0.393913</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>0.321260</td>\n",
       "      <td>0.886595</td>\n",
       "      <td>-0.141000</td>\n",
       "      <td>1.195850</td>\n",
       "      <td>-0.524238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519916</td>\n",
       "      <td>-0.763471</td>\n",
       "      <td>-1.257727</td>\n",
       "      <td>-0.439297</td>\n",
       "      <td>-0.351291</td>\n",
       "      <td>-0.623682</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>-0.400558</td>\n",
       "      <td>-0.913325</td>\n",
       "      <td>0.705828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054587</td>\n",
       "      <td>-0.553129</td>\n",
       "      <td>0.754823</td>\n",
       "      <td>-0.394011</td>\n",
       "      <td>-0.698774</td>\n",
       "      <td>-0.266880</td>\n",
       "      <td>0.886639</td>\n",
       "      <td>-0.141024</td>\n",
       "      <td>1.201248</td>\n",
       "      <td>-0.524308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522510</td>\n",
       "      <td>-0.763478</td>\n",
       "      <td>-1.258909</td>\n",
       "      <td>-0.149907</td>\n",
       "      <td>-0.350716</td>\n",
       "      <td>-0.623032</td>\n",
       "      <td>-0.017234</td>\n",
       "      <td>-0.400562</td>\n",
       "      <td>-0.914056</td>\n",
       "      <td>0.218593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045943</td>\n",
       "      <td>-0.551243</td>\n",
       "      <td>0.726917</td>\n",
       "      <td>-0.393997</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.699580</td>\n",
       "      <td>0.897675</td>\n",
       "      <td>-0.116077</td>\n",
       "      <td>1.201022</td>\n",
       "      <td>-0.523883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523062</td>\n",
       "      <td>-0.763479</td>\n",
       "      <td>-1.259232</td>\n",
       "      <td>0.145985</td>\n",
       "      <td>-0.348852</td>\n",
       "      <td>-0.620142</td>\n",
       "      <td>-0.015135</td>\n",
       "      <td>-0.400553</td>\n",
       "      <td>-0.912443</td>\n",
       "      <td>0.533490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038098</td>\n",
       "      <td>-0.549365</td>\n",
       "      <td>0.752191</td>\n",
       "      <td>-0.394041</td>\n",
       "      <td>-0.702816</td>\n",
       "      <td>2.260389</td>\n",
       "      <td>0.907779</td>\n",
       "      <td>-0.130346</td>\n",
       "      <td>1.204990</td>\n",
       "      <td>-0.524269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521765</td>\n",
       "      <td>-0.763474</td>\n",
       "      <td>-1.258165</td>\n",
       "      <td>-0.176094</td>\n",
       "      <td>-0.347060</td>\n",
       "      <td>-0.619151</td>\n",
       "      <td>-0.013759</td>\n",
       "      <td>-0.400559</td>\n",
       "      <td>-0.913492</td>\n",
       "      <td>0.562119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "0     0.055870   -0.546828    0.725530   -0.393761   -0.680020    -0.428085   \n",
       "1     0.056545   -0.545491    0.754858   -0.393913   -0.689658     0.321260   \n",
       "2     0.054587   -0.553129    0.754823   -0.394011   -0.698774    -0.266880   \n",
       "3     0.045943   -0.551243    0.726917   -0.393997   -0.697102    -0.699580   \n",
       "4     0.038098   -0.549365    0.752191   -0.394041   -0.702816     2.260389   \n",
       "\n",
       "   T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  LL_ymag_min  \\\n",
       "0     0.860379   -0.148110    1.180617   -0.523874  ...     0.519750   \n",
       "1     0.886595   -0.141000    1.195850   -0.524238  ...     0.519916   \n",
       "2     0.886639   -0.141024    1.201248   -0.524308  ...     0.522510   \n",
       "3     0.897675   -0.116077    1.201022   -0.523883  ...     0.523062   \n",
       "4     0.907779   -0.130346    1.204990   -0.524269  ...     0.521765   \n",
       "\n",
       "   LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  \\\n",
       "0    -0.763476    -1.258551      0.441264     -0.350861    -0.623732   \n",
       "1    -0.763471    -1.257727     -0.439297     -0.351291    -0.623682   \n",
       "2    -0.763478    -1.258909     -0.149907     -0.350716    -0.623032   \n",
       "3    -0.763479    -1.259232      0.145985     -0.348852    -0.620142   \n",
       "4    -0.763474    -1.258165     -0.176094     -0.347060    -0.619151   \n",
       "\n",
       "   LL_zmag_min  LL_zmag_var  LL_zmag_std  LL_zmag_skew  \n",
       "0    -0.017723    -0.400560    -0.913563      0.204309  \n",
       "1    -0.018691    -0.400558    -0.913325      0.705828  \n",
       "2    -0.017234    -0.400562    -0.914056      0.218593  \n",
       "3    -0.015135    -0.400553    -0.912443      0.533490  \n",
       "4    -0.013759    -0.400559    -0.913492      0.562119  \n",
       "\n",
       "[5 rows x 270 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df_filtered.drop(['activity'], axis=1)\n",
    "\n",
    "X.head()\n",
    "# head()는 첫 5행만 출력함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b14f75-c2d5-4a02-b621-9b7bd6eb75dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    480\n",
       "18    480\n",
       "6     480\n",
       "10    480\n",
       "4     480\n",
       "3     480\n",
       "2     480\n",
       "15    480\n",
       "11    480\n",
       "17    480\n",
       "13    480\n",
       "16    480\n",
       "9     480\n",
       "14    480\n",
       "5     480\n",
       "0     480\n",
       "8     480\n",
       "7     480\n",
       "1     480\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df_filtered['activity']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f8bdac-379a-432e-9b5a-12dc7aa991f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding 하기\n",
    "\n",
    "y = pd.get_dummies(y).values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24d8694d-8983-4998-b5e5-8f2fe36bf397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_min</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>0.419664</td>\n",
       "      <td>-0.267410</td>\n",
       "      <td>0.857712</td>\n",
       "      <td>-0.390597</td>\n",
       "      <td>-0.599402</td>\n",
       "      <td>1.766596</td>\n",
       "      <td>0.482579</td>\n",
       "      <td>0.143300</td>\n",
       "      <td>0.265497</td>\n",
       "      <td>0.011474</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.464914</td>\n",
       "      <td>-0.601034</td>\n",
       "      <td>-0.523085</td>\n",
       "      <td>0.232655</td>\n",
       "      <td>0.164311</td>\n",
       "      <td>0.185977</td>\n",
       "      <td>0.191275</td>\n",
       "      <td>-0.180076</td>\n",
       "      <td>0.084982</td>\n",
       "      <td>-0.048766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>0.289253</td>\n",
       "      <td>-0.130556</td>\n",
       "      <td>0.213787</td>\n",
       "      <td>-0.261283</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-0.372821</td>\n",
       "      <td>0.436366</td>\n",
       "      <td>0.152278</td>\n",
       "      <td>0.322950</td>\n",
       "      <td>-0.294576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289184</td>\n",
       "      <td>1.336399</td>\n",
       "      <td>1.410150</td>\n",
       "      <td>-0.814559</td>\n",
       "      <td>0.074818</td>\n",
       "      <td>-0.022785</td>\n",
       "      <td>-0.026008</td>\n",
       "      <td>-0.196340</td>\n",
       "      <td>0.046971</td>\n",
       "      <td>-1.477950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>0.444226</td>\n",
       "      <td>0.915389</td>\n",
       "      <td>-2.387490</td>\n",
       "      <td>0.204361</td>\n",
       "      <td>0.799904</td>\n",
       "      <td>-0.827652</td>\n",
       "      <td>0.043703</td>\n",
       "      <td>1.562785</td>\n",
       "      <td>-2.802558</td>\n",
       "      <td>2.130162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241955</td>\n",
       "      <td>0.383108</td>\n",
       "      <td>0.710981</td>\n",
       "      <td>-1.315558</td>\n",
       "      <td>-0.538672</td>\n",
       "      <td>0.228596</td>\n",
       "      <td>-1.480582</td>\n",
       "      <td>1.839287</td>\n",
       "      <td>2.296963</td>\n",
       "      <td>-0.709158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.496390</td>\n",
       "      <td>-0.415049</td>\n",
       "      <td>1.058778</td>\n",
       "      <td>-0.394059</td>\n",
       "      <td>-0.705942</td>\n",
       "      <td>-0.459722</td>\n",
       "      <td>-0.045746</td>\n",
       "      <td>-0.608613</td>\n",
       "      <td>0.669579</td>\n",
       "      <td>-0.523371</td>\n",
       "      <td>...</td>\n",
       "      <td>1.269129</td>\n",
       "      <td>-0.763475</td>\n",
       "      <td>-1.258426</td>\n",
       "      <td>0.286603</td>\n",
       "      <td>1.653274</td>\n",
       "      <td>1.306226</td>\n",
       "      <td>1.911123</td>\n",
       "      <td>-0.400556</td>\n",
       "      <td>-0.912833</td>\n",
       "      <td>-0.056411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>0.538101</td>\n",
       "      <td>-0.008419</td>\n",
       "      <td>0.135068</td>\n",
       "      <td>-0.261913</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>-0.541621</td>\n",
       "      <td>0.121592</td>\n",
       "      <td>0.302675</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>-0.170676</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.371487</td>\n",
       "      <td>0.405519</td>\n",
       "      <td>0.730228</td>\n",
       "      <td>-0.567322</td>\n",
       "      <td>-0.073746</td>\n",
       "      <td>-0.004433</td>\n",
       "      <td>-0.195205</td>\n",
       "      <td>-0.131990</td>\n",
       "      <td>0.189819</td>\n",
       "      <td>-0.729581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>0.448697</td>\n",
       "      <td>-0.124381</td>\n",
       "      <td>0.328237</td>\n",
       "      <td>-0.307457</td>\n",
       "      <td>-0.138625</td>\n",
       "      <td>-0.462540</td>\n",
       "      <td>0.429048</td>\n",
       "      <td>0.118952</td>\n",
       "      <td>0.069884</td>\n",
       "      <td>-0.128048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357864</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.445775</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.274422</td>\n",
       "      <td>0.274102</td>\n",
       "      <td>0.428105</td>\n",
       "      <td>-0.309710</td>\n",
       "      <td>-0.277118</td>\n",
       "      <td>1.695668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>0.079846</td>\n",
       "      <td>-0.287456</td>\n",
       "      <td>-0.615208</td>\n",
       "      <td>-0.257268</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>-1.447639</td>\n",
       "      <td>0.592660</td>\n",
       "      <td>0.114140</td>\n",
       "      <td>0.305071</td>\n",
       "      <td>-0.256926</td>\n",
       "      <td>...</td>\n",
       "      <td>1.806422</td>\n",
       "      <td>-0.533621</td>\n",
       "      <td>-0.381912</td>\n",
       "      <td>0.502539</td>\n",
       "      <td>-0.212061</td>\n",
       "      <td>-0.170021</td>\n",
       "      <td>-0.120088</td>\n",
       "      <td>-0.231851</td>\n",
       "      <td>-0.041680</td>\n",
       "      <td>0.676274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>0.407423</td>\n",
       "      <td>0.029474</td>\n",
       "      <td>0.181631</td>\n",
       "      <td>-0.247453</td>\n",
       "      <td>0.034875</td>\n",
       "      <td>-0.042758</td>\n",
       "      <td>0.554886</td>\n",
       "      <td>0.498584</td>\n",
       "      <td>0.363278</td>\n",
       "      <td>-0.156013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479237</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>0.474054</td>\n",
       "      <td>-1.003366</td>\n",
       "      <td>0.144897</td>\n",
       "      <td>0.166931</td>\n",
       "      <td>0.271166</td>\n",
       "      <td>-0.325120</td>\n",
       "      <td>-0.334718</td>\n",
       "      <td>0.993850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>0.077620</td>\n",
       "      <td>-0.529928</td>\n",
       "      <td>0.708385</td>\n",
       "      <td>-0.392884</td>\n",
       "      <td>-0.647255</td>\n",
       "      <td>-1.301710</td>\n",
       "      <td>-0.200471</td>\n",
       "      <td>-0.681803</td>\n",
       "      <td>0.576770</td>\n",
       "      <td>-0.523078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.962090</td>\n",
       "      <td>-0.469174</td>\n",
       "      <td>-0.265364</td>\n",
       "      <td>0.052740</td>\n",
       "      <td>0.519024</td>\n",
       "      <td>0.595645</td>\n",
       "      <td>0.377782</td>\n",
       "      <td>0.188570</td>\n",
       "      <td>0.726753</td>\n",
       "      <td>-0.505567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>-0.172971</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>-0.640808</td>\n",
       "      <td>-0.046015</td>\n",
       "      <td>0.440333</td>\n",
       "      <td>-1.366976</td>\n",
       "      <td>0.725592</td>\n",
       "      <td>0.062499</td>\n",
       "      <td>0.824522</td>\n",
       "      <td>-0.431907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.964684</td>\n",
       "      <td>-0.281622</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.092235</td>\n",
       "      <td>0.981501</td>\n",
       "      <td>1.128616</td>\n",
       "      <td>0.146976</td>\n",
       "      <td>1.843957</td>\n",
       "      <td>2.300321</td>\n",
       "      <td>-2.080342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6840 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "3482     0.419664   -0.267410    0.857712   -0.390597   -0.599402   \n",
       "5048     0.289253   -0.130556    0.213787   -0.261283   -0.001363   \n",
       "8682     0.444226    0.915389   -2.387490    0.204361    0.799904   \n",
       "85       0.496390   -0.415049    1.058778   -0.394059   -0.705942   \n",
       "4265     0.538101   -0.008419    0.135068   -0.261913   -0.003057   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "4373     0.448697   -0.124381    0.328237   -0.307457   -0.138625   \n",
       "7891     0.079846   -0.287456   -0.615208   -0.257268    0.009345   \n",
       "4859     0.407423    0.029474    0.181631   -0.247453    0.034875   \n",
       "3264     0.077620   -0.529928    0.708385   -0.392884   -0.647255   \n",
       "2732    -0.172971    0.018478   -0.640808   -0.046015    0.440333   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "3482     1.766596     0.482579    0.143300    0.265497    0.011474  ...   \n",
       "5048    -0.372821     0.436366    0.152278    0.322950   -0.294576  ...   \n",
       "8682    -0.827652     0.043703    1.562785   -2.802558    2.130162  ...   \n",
       "85      -0.459722    -0.045746   -0.608613    0.669579   -0.523371  ...   \n",
       "4265    -0.541621     0.121592    0.302675    0.079200   -0.170676  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "4373    -0.462540     0.429048    0.118952    0.069884   -0.128048  ...   \n",
       "7891    -1.447639     0.592660    0.114140    0.305071   -0.256926  ...   \n",
       "4859    -0.042758     0.554886    0.498584    0.363278   -0.156013  ...   \n",
       "3264    -1.301710    -0.200471   -0.681803    0.576770   -0.523078  ...   \n",
       "2732    -1.366976     0.725592    0.062499    0.824522   -0.431907  ...   \n",
       "\n",
       "      LL_ymag_min  LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  \\\n",
       "3482    -1.464914    -0.601034    -0.523085      0.232655      0.164311   \n",
       "5048    -0.289184     1.336399     1.410150     -0.814559      0.074818   \n",
       "8682     0.241955     0.383108     0.710981     -1.315558     -0.538672   \n",
       "85       1.269129    -0.763475    -1.258426      0.286603      1.653274   \n",
       "4265    -2.371487     0.405519     0.730228     -0.567322     -0.073746   \n",
       "...           ...          ...          ...           ...           ...   \n",
       "4373     0.357864     0.096386     0.445775      0.001467      0.274422   \n",
       "7891     1.806422    -0.533621    -0.381912      0.502539     -0.212061   \n",
       "4859     0.479237     0.124998     0.474054     -1.003366      0.144897   \n",
       "3264    -0.962090    -0.469174    -0.265364      0.052740      0.519024   \n",
       "2732    -0.964684    -0.281622     0.014920      0.092235      0.981501   \n",
       "\n",
       "      LL_zmag_max  LL_zmag_min  LL_zmag_var  LL_zmag_std  LL_zmag_skew  \n",
       "3482     0.185977     0.191275    -0.180076     0.084982     -0.048766  \n",
       "5048    -0.022785    -0.026008    -0.196340     0.046971     -1.477950  \n",
       "8682     0.228596    -1.480582     1.839287     2.296963     -0.709158  \n",
       "85       1.306226     1.911123    -0.400556    -0.912833     -0.056411  \n",
       "4265    -0.004433    -0.195205    -0.131990     0.189819     -0.729581  \n",
       "...           ...          ...          ...          ...           ...  \n",
       "4373     0.274102     0.428105    -0.309710    -0.277118      1.695668  \n",
       "7891    -0.170021    -0.120088    -0.231851    -0.041680      0.676274  \n",
       "4859     0.166931     0.271166    -0.325120    -0.334718      0.993850  \n",
       "3264     0.595645     0.377782     0.188570     0.726753     -0.505567  \n",
       "2732     1.128616     0.146976     1.843957     2.300321     -2.080342  \n",
       "\n",
       "[6840 rows x 270 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "# random_state는 데이터를 무작위로 나누거나 섞을 때 사용되는 난수 발생기의 시드(seed) 값\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277cffe-6f0e-4729-95f8-9eab11e03c1c",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da29bb43-0622-4259-bdc8-e801aee91e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00070fa-a966-4840-923e-7619203d7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    n_outputs,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks, # 해당 파라미터 값을 변경하여 적용한다.\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_outputs, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b89b8634-21e1-43eb-b5ed-d8f61f4acfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06956998 -0.33279226  0.28423533 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.49655011  0.00562165  0.46909816 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.08805305 -0.43553441  0.55706541 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.11132853  0.94972965 -0.48450524 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.15083931 -0.07946817  0.10737598 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.51992305 -0.01789223  0.25648989 ...  1.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Merge train and test X/y data to apply sequence transformation function\n",
    "y_train_array = np.array(y_train)\n",
    "# np.c_ : 배열을 열 방향으로 이어붙인다.\n",
    "train_set = np.c_[X_train, y_train_array]\n",
    "\n",
    "y_test_array = np.array(y_test)\n",
    "test_set = np.c_[X_test, y_test_array]\n",
    "\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf04234a-e355-43ed-ac4f-9a909ef99564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6836, 5, 270) (6836, 19)\n",
      "(2276, 5, 270) (2276, 19)\n"
     ]
    }
   ],
   "source": [
    "# Apply sequence transformation using time step of 25 for both train and test data\n",
    "# All sensing modalities are recorded at a sampling rate of 50 Hz, which is considered sufficient for capturing human activity.\n",
    "\n",
    "X_train, y_train = split_sequences(train_set, 5, X_test.shape[1])\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_test, y_test = split_sequences(test_set, 5, X_test.shape[1])\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a36e2e9-1c2d-4ee3-ab93-a4a71de826ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "idx = np.random.permutation(len(X_train))\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0\n",
    "\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f515f125-b1b1-4ca6-9cc2-c8133ed0b0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 270 19\n"
     ]
    }
   ],
   "source": [
    "# 각각 스텝 수, feature 수, label 수\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "print(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a0c82b-3602-4f9b-b0ce-bcc750e10eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 270)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "575508a7-6523-4d2a-95cf-fcfa98dd2a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Choij\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 270)]             0         []                            \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 5, 270)               1109262   ['input_1[0][0]',             \n",
      " iHeadAttention)                                                     'input_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 5, 270)               0         ['multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 5, 270)               540       ['dropout[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 5, 270)               0         ['layer_normalization[0][0]', \n",
      " Lambda)                                                             'input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 5, 4)                 1084      ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 5, 4)                 0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 5, 270)               1350      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 5, 270)               540       ['conv1d_1[0][0]']            \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 5, 270)               0         ['layer_normalization_1[0][0]'\n",
      " OpLambda)                                                          , 'tf.__operators__.add[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 5, 270)               1109262   ['tf.__operators__.add_1[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 5, 270)               0         ['multi_head_attention_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 5, 270)               540       ['dropout_2[0][0]']           \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 5, 270)               0         ['layer_normalization_2[0][0]'\n",
      " OpLambda)                                                          , 'tf.__operators__.add_1[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 5, 4)                 1084      ['tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 5, 4)                 0         ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 5, 270)               1350      ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 5, 270)               540       ['conv1d_3[0][0]']            \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 5, 270)               0         ['layer_normalization_3[0][0]'\n",
      " OpLambda)                                                          , 'tf.__operators__.add_2[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 5, 270)               1109262   ['tf.__operators__.add_3[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'tf.__operators__.add_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 5, 270)               0         ['multi_head_attention_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 5, 270)               540       ['dropout_4[0][0]']           \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, 5, 270)               0         ['layer_normalization_4[0][0]'\n",
      " OpLambda)                                                          , 'tf.__operators__.add_3[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 5, 4)                 1084      ['tf.__operators__.add_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 5, 4)                 0         ['conv1d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 5, 270)               1350      ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 5, 270)               540       ['conv1d_5[0][0]']            \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, 5, 270)               0         ['layer_normalization_5[0][0]'\n",
      " OpLambda)                                                          , 'tf.__operators__.add_4[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 5, 270)               1109262   ['tf.__operators__.add_5[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'tf.__operators__.add_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 5, 270)               0         ['multi_head_attention_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 5, 270)               540       ['dropout_6[0][0]']           \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 5, 270)               0         ['layer_normalization_6[0][0]'\n",
      " OpLambda)                                                          , 'tf.__operators__.add_5[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 5, 4)                 1084      ['tf.__operators__.add_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 5, 4)                 0         ['conv1d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 5, 270)               1350      ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 5, 270)               540       ['conv1d_7[0][0]']            \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, 5, 270)               0         ['layer_normalization_7[0][0]'\n",
      " OpLambda)                                                          , 'tf.__operators__.add_6[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 270)                  0         ['tf.__operators__.add_7[0][0]\n",
      " GlobalAveragePooling1D)                                            ']                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  34688     ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 19)                   2451      ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4488243 (17.12 MB)\n",
      "Trainable params: 4488243 (17.12 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\Choij\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Choij\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "86/86 [==============================] - 11s 56ms/step - loss: 3.1148 - accuracy: 0.0988 - val_loss: 2.7417 - val_accuracy: 0.1594\n",
      "Epoch 2/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.8067 - accuracy: 0.1324 - val_loss: 2.7526 - val_accuracy: 0.1681\n",
      "Epoch 3/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.7695 - accuracy: 0.1467 - val_loss: 2.6681 - val_accuracy: 0.1901\n",
      "Epoch 4/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.7238 - accuracy: 0.1591 - val_loss: 2.6440 - val_accuracy: 0.1944\n",
      "Epoch 5/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.6754 - accuracy: 0.1699 - val_loss: 2.5688 - val_accuracy: 0.2039\n",
      "Epoch 6/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.6164 - accuracy: 0.1889 - val_loss: 2.5112 - val_accuracy: 0.2193\n",
      "Epoch 7/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.5892 - accuracy: 0.2032 - val_loss: 2.4830 - val_accuracy: 0.2120\n",
      "Epoch 8/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.5724 - accuracy: 0.2056 - val_loss: 2.4832 - val_accuracy: 0.2149\n",
      "Epoch 9/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.5545 - accuracy: 0.1988 - val_loss: 2.4546 - val_accuracy: 0.2244\n",
      "Epoch 10/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.5079 - accuracy: 0.2196 - val_loss: 2.4445 - val_accuracy: 0.2193\n",
      "Epoch 11/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.4970 - accuracy: 0.2134 - val_loss: 2.4097 - val_accuracy: 0.2317\n",
      "Epoch 12/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.4655 - accuracy: 0.2167 - val_loss: 2.4122 - val_accuracy: 0.2171\n",
      "Epoch 13/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 2.4618 - accuracy: 0.2222 - val_loss: 2.4070 - val_accuracy: 0.2142\n",
      "Epoch 14/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.4097 - accuracy: 0.2308 - val_loss: 2.4470 - val_accuracy: 0.2061\n",
      "Epoch 15/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.4069 - accuracy: 0.2273 - val_loss: 2.4029 - val_accuracy: 0.2171\n",
      "Epoch 16/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.3823 - accuracy: 0.2416 - val_loss: 2.3996 - val_accuracy: 0.2251\n",
      "Epoch 17/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.3696 - accuracy: 0.2410 - val_loss: 2.3863 - val_accuracy: 0.2346\n",
      "Epoch 18/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.3530 - accuracy: 0.2452 - val_loss: 2.4169 - val_accuracy: 0.2200\n",
      "Epoch 19/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.3510 - accuracy: 0.2454 - val_loss: 2.3862 - val_accuracy: 0.2098\n",
      "Epoch 20/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.3074 - accuracy: 0.2540 - val_loss: 2.3742 - val_accuracy: 0.2193\n",
      "Epoch 21/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.2987 - accuracy: 0.2502 - val_loss: 2.3847 - val_accuracy: 0.2171\n",
      "Epoch 22/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.2773 - accuracy: 0.2573 - val_loss: 2.4053 - val_accuracy: 0.2251\n",
      "Epoch 23/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.3001 - accuracy: 0.2522 - val_loss: 2.3723 - val_accuracy: 0.2069\n",
      "Epoch 24/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 2.2664 - accuracy: 0.2595 - val_loss: 2.3752 - val_accuracy: 0.2171\n",
      "Epoch 25/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.2911 - accuracy: 0.2612 - val_loss: 2.3989 - val_accuracy: 0.2405\n",
      "Epoch 26/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.3042 - accuracy: 0.2553 - val_loss: 2.3807 - val_accuracy: 0.2259\n",
      "Epoch 27/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.2845 - accuracy: 0.2569 - val_loss: 2.3997 - val_accuracy: 0.2303\n",
      "Epoch 28/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.3159 - accuracy: 0.2496 - val_loss: 2.3531 - val_accuracy: 0.2135\n",
      "Epoch 29/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.2742 - accuracy: 0.2604 - val_loss: 2.3605 - val_accuracy: 0.2142\n",
      "Epoch 30/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.2988 - accuracy: 0.2518 - val_loss: 2.3601 - val_accuracy: 0.2076\n",
      "Epoch 31/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.2695 - accuracy: 0.2579 - val_loss: 2.3974 - val_accuracy: 0.2222\n",
      "Epoch 32/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.2387 - accuracy: 0.2701 - val_loss: 2.3580 - val_accuracy: 0.2273\n",
      "Epoch 33/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.2270 - accuracy: 0.2630 - val_loss: 2.2976 - val_accuracy: 0.2230\n",
      "Epoch 34/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 2.2566 - accuracy: 0.2548 - val_loss: 2.3577 - val_accuracy: 0.2069\n",
      "Epoch 35/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.2496 - accuracy: 0.2670 - val_loss: 2.3483 - val_accuracy: 0.2178\n",
      "Epoch 36/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.2512 - accuracy: 0.2646 - val_loss: 2.3509 - val_accuracy: 0.1959\n",
      "Epoch 37/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.2723 - accuracy: 0.2447 - val_loss: 2.3443 - val_accuracy: 0.2266\n",
      "Epoch 38/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.2231 - accuracy: 0.2685 - val_loss: 2.3238 - val_accuracy: 0.2200\n",
      "Epoch 39/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.1889 - accuracy: 0.2868 - val_loss: 2.3177 - val_accuracy: 0.2266\n",
      "Epoch 40/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.1741 - accuracy: 0.2811 - val_loss: 2.3113 - val_accuracy: 0.2303\n",
      "Epoch 41/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.1758 - accuracy: 0.2838 - val_loss: 2.3414 - val_accuracy: 0.2295\n",
      "Epoch 42/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.1676 - accuracy: 0.2802 - val_loss: 2.3172 - val_accuracy: 0.2164\n",
      "Epoch 43/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.1482 - accuracy: 0.2847 - val_loss: 2.3196 - val_accuracy: 0.2156\n",
      "Epoch 44/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 2.1289 - accuracy: 0.2897 - val_loss: 2.3657 - val_accuracy: 0.2135\n",
      "Epoch 45/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.1465 - accuracy: 0.2769 - val_loss: 2.3309 - val_accuracy: 0.2156\n",
      "Epoch 46/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.1117 - accuracy: 0.2891 - val_loss: 2.3105 - val_accuracy: 0.2164\n",
      "Epoch 47/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.0941 - accuracy: 0.2884 - val_loss: 2.2968 - val_accuracy: 0.2142\n",
      "Epoch 48/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.0879 - accuracy: 0.2979 - val_loss: 2.3154 - val_accuracy: 0.2069\n",
      "Epoch 49/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.0753 - accuracy: 0.3029 - val_loss: 2.3584 - val_accuracy: 0.2018\n",
      "Epoch 50/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.0681 - accuracy: 0.2994 - val_loss: 2.3456 - val_accuracy: 0.2142\n",
      "Epoch 51/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.0684 - accuracy: 0.2979 - val_loss: 2.2884 - val_accuracy: 0.2171\n",
      "Epoch 52/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.0430 - accuracy: 0.3019 - val_loss: 2.3263 - val_accuracy: 0.2186\n",
      "Epoch 53/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 2.0477 - accuracy: 0.3072 - val_loss: 2.3460 - val_accuracy: 0.2025\n",
      "Epoch 54/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.0370 - accuracy: 0.3063 - val_loss: 2.3700 - val_accuracy: 0.2003\n",
      "Epoch 55/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.0250 - accuracy: 0.3107 - val_loss: 2.3671 - val_accuracy: 0.2113\n",
      "Epoch 56/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 2.0037 - accuracy: 0.3118 - val_loss: 2.3827 - val_accuracy: 0.2105\n",
      "Epoch 57/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 2.0032 - accuracy: 0.3147 - val_loss: 2.3506 - val_accuracy: 0.2105\n",
      "Epoch 58/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 1.9817 - accuracy: 0.3136 - val_loss: 2.3241 - val_accuracy: 0.2076\n",
      "Epoch 59/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.9572 - accuracy: 0.3244 - val_loss: 2.3065 - val_accuracy: 0.2091\n",
      "Epoch 60/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.9742 - accuracy: 0.3301 - val_loss: 2.3727 - val_accuracy: 0.1966\n",
      "Epoch 61/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.9588 - accuracy: 0.3283 - val_loss: 2.3892 - val_accuracy: 0.1981\n",
      "Epoch 62/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.9545 - accuracy: 0.3281 - val_loss: 2.3782 - val_accuracy: 0.1988\n",
      "Epoch 63/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 1.9360 - accuracy: 0.3294 - val_loss: 2.3934 - val_accuracy: 0.2047\n",
      "Epoch 64/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.9292 - accuracy: 0.3387 - val_loss: 2.4061 - val_accuracy: 0.1981\n",
      "Epoch 65/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.8957 - accuracy: 0.3411 - val_loss: 2.4185 - val_accuracy: 0.2069\n",
      "Epoch 66/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.8962 - accuracy: 0.3453 - val_loss: 2.4058 - val_accuracy: 0.2076\n",
      "Epoch 67/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.9131 - accuracy: 0.3409 - val_loss: 2.3574 - val_accuracy: 0.2098\n",
      "Epoch 68/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.8925 - accuracy: 0.3403 - val_loss: 2.4020 - val_accuracy: 0.2032\n",
      "Epoch 69/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.9027 - accuracy: 0.3391 - val_loss: 2.4107 - val_accuracy: 0.2032\n",
      "Epoch 70/150\n",
      "86/86 [==============================] - 5s 53ms/step - loss: 1.8932 - accuracy: 0.3334 - val_loss: 2.4999 - val_accuracy: 0.2069\n",
      "Epoch 71/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.8943 - accuracy: 0.3420 - val_loss: 2.3805 - val_accuracy: 0.1959\n",
      "Epoch 72/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.8711 - accuracy: 0.3455 - val_loss: 2.4083 - val_accuracy: 0.2127\n",
      "Epoch 73/150\n",
      "86/86 [==============================] - 5s 53ms/step - loss: 1.8548 - accuracy: 0.3495 - val_loss: 2.4799 - val_accuracy: 0.1966\n",
      "Epoch 74/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.8222 - accuracy: 0.3617 - val_loss: 2.3879 - val_accuracy: 0.2039\n",
      "Epoch 75/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.8368 - accuracy: 0.3601 - val_loss: 2.3772 - val_accuracy: 0.2113\n",
      "Epoch 76/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.8252 - accuracy: 0.3619 - val_loss: 2.4335 - val_accuracy: 0.2054\n",
      "Epoch 77/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.8195 - accuracy: 0.3478 - val_loss: 2.4762 - val_accuracy: 0.2061\n",
      "Epoch 78/150\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 1.8072 - accuracy: 0.3793 - val_loss: 2.4887 - val_accuracy: 0.1893\n",
      "Epoch 79/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.8236 - accuracy: 0.3634 - val_loss: 2.4843 - val_accuracy: 0.1981\n",
      "Epoch 80/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.8009 - accuracy: 0.3713 - val_loss: 2.4157 - val_accuracy: 0.2061\n",
      "Epoch 81/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.8034 - accuracy: 0.3603 - val_loss: 2.4615 - val_accuracy: 0.1974\n",
      "Epoch 82/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.7856 - accuracy: 0.3608 - val_loss: 2.4728 - val_accuracy: 0.2083\n",
      "Epoch 83/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.7674 - accuracy: 0.3685 - val_loss: 2.4976 - val_accuracy: 0.2018\n",
      "Epoch 84/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.7381 - accuracy: 0.3817 - val_loss: 2.5047 - val_accuracy: 0.2076\n",
      "Epoch 85/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.7498 - accuracy: 0.3833 - val_loss: 2.5326 - val_accuracy: 0.1988\n",
      "Epoch 86/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.7197 - accuracy: 0.3824 - val_loss: 2.5831 - val_accuracy: 0.2054\n",
      "Epoch 87/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.7247 - accuracy: 0.3762 - val_loss: 2.5028 - val_accuracy: 0.2135\n",
      "Epoch 88/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.7388 - accuracy: 0.3844 - val_loss: 2.5763 - val_accuracy: 0.2135\n",
      "Epoch 89/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.7095 - accuracy: 0.3998 - val_loss: 2.5904 - val_accuracy: 0.2010\n",
      "Epoch 90/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.7161 - accuracy: 0.3928 - val_loss: 2.5718 - val_accuracy: 0.2025\n",
      "Epoch 91/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.7158 - accuracy: 0.3934 - val_loss: 2.5281 - val_accuracy: 0.1893\n",
      "Epoch 92/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.7201 - accuracy: 0.3972 - val_loss: 2.5221 - val_accuracy: 0.1996\n",
      "Epoch 93/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.7147 - accuracy: 0.3939 - val_loss: 2.4780 - val_accuracy: 0.2120\n",
      "Epoch 94/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.6757 - accuracy: 0.4062 - val_loss: 2.5310 - val_accuracy: 0.1930\n",
      "Epoch 95/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.6769 - accuracy: 0.4064 - val_loss: 2.5923 - val_accuracy: 0.1996\n",
      "Epoch 96/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.6561 - accuracy: 0.4128 - val_loss: 2.5970 - val_accuracy: 0.2039\n",
      "Epoch 97/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.6453 - accuracy: 0.4117 - val_loss: 2.6136 - val_accuracy: 0.1908\n",
      "Epoch 98/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.6318 - accuracy: 0.4166 - val_loss: 2.5672 - val_accuracy: 0.1981\n",
      "Epoch 99/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.6268 - accuracy: 0.4097 - val_loss: 2.5783 - val_accuracy: 0.1871\n",
      "Epoch 100/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.5963 - accuracy: 0.4221 - val_loss: 2.6281 - val_accuracy: 0.1981\n",
      "Epoch 101/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.5967 - accuracy: 0.4270 - val_loss: 2.6797 - val_accuracy: 0.1966\n",
      "Epoch 102/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.5968 - accuracy: 0.4283 - val_loss: 2.6760 - val_accuracy: 0.1937\n",
      "Epoch 103/150\n",
      "86/86 [==============================] - 5s 53ms/step - loss: 1.6120 - accuracy: 0.4100 - val_loss: 2.7366 - val_accuracy: 0.1820\n",
      "Epoch 104/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.5981 - accuracy: 0.4289 - val_loss: 2.7006 - val_accuracy: 0.1996\n",
      "Epoch 105/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.6216 - accuracy: 0.4161 - val_loss: 2.6988 - val_accuracy: 0.1930\n",
      "Epoch 106/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.6172 - accuracy: 0.4314 - val_loss: 2.6690 - val_accuracy: 0.1966\n",
      "Epoch 107/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.6035 - accuracy: 0.4236 - val_loss: 2.7002 - val_accuracy: 0.2047\n",
      "Epoch 108/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.5646 - accuracy: 0.4367 - val_loss: 2.6955 - val_accuracy: 0.1915\n",
      "Epoch 109/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.5548 - accuracy: 0.4340 - val_loss: 2.6977 - val_accuracy: 0.1915\n",
      "Epoch 110/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.5133 - accuracy: 0.4530 - val_loss: 2.7770 - val_accuracy: 0.1835\n",
      "Epoch 111/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.5011 - accuracy: 0.4554 - val_loss: 2.8443 - val_accuracy: 0.1915\n",
      "Epoch 112/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.4794 - accuracy: 0.4589 - val_loss: 2.8532 - val_accuracy: 0.1988\n",
      "Epoch 113/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.4649 - accuracy: 0.4687 - val_loss: 2.8594 - val_accuracy: 0.1901\n",
      "Epoch 114/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.4721 - accuracy: 0.4669 - val_loss: 2.8427 - val_accuracy: 0.1703\n",
      "Epoch 115/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.4589 - accuracy: 0.4631 - val_loss: 2.9258 - val_accuracy: 0.1820\n",
      "Epoch 116/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.4371 - accuracy: 0.4795 - val_loss: 2.9206 - val_accuracy: 0.1923\n",
      "Epoch 117/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.4303 - accuracy: 0.4823 - val_loss: 2.9471 - val_accuracy: 0.1857\n",
      "Epoch 118/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.4423 - accuracy: 0.4812 - val_loss: 2.9308 - val_accuracy: 0.1696\n",
      "Epoch 119/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.4359 - accuracy: 0.4846 - val_loss: 2.9309 - val_accuracy: 0.1791\n",
      "Epoch 120/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.4068 - accuracy: 0.4779 - val_loss: 2.9292 - val_accuracy: 0.1944\n",
      "Epoch 121/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.4007 - accuracy: 0.4951 - val_loss: 3.0310 - val_accuracy: 0.1893\n",
      "Epoch 122/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.3869 - accuracy: 0.4998 - val_loss: 2.9509 - val_accuracy: 0.1952\n",
      "Epoch 123/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.3789 - accuracy: 0.4973 - val_loss: 2.9116 - val_accuracy: 0.1937\n",
      "Epoch 124/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.3693 - accuracy: 0.4982 - val_loss: 3.0714 - val_accuracy: 0.1915\n",
      "Epoch 125/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.3723 - accuracy: 0.5093 - val_loss: 3.0647 - val_accuracy: 0.1842\n",
      "Epoch 126/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.3661 - accuracy: 0.5027 - val_loss: 3.0306 - val_accuracy: 0.1747\n",
      "Epoch 127/150\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 1.3732 - accuracy: 0.5018 - val_loss: 3.0596 - val_accuracy: 0.1820\n",
      "Epoch 128/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.3652 - accuracy: 0.5015 - val_loss: 3.1086 - val_accuracy: 0.1784\n",
      "Epoch 129/150\n",
      "86/86 [==============================] - 5s 53ms/step - loss: 1.3507 - accuracy: 0.5108 - val_loss: 3.1456 - val_accuracy: 0.1667\n",
      "Epoch 130/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.3097 - accuracy: 0.5203 - val_loss: 3.1488 - val_accuracy: 0.1864\n",
      "Epoch 131/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.3297 - accuracy: 0.5166 - val_loss: 3.1141 - val_accuracy: 0.1776\n",
      "Epoch 132/150\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 1.2959 - accuracy: 0.5342 - val_loss: 3.2004 - val_accuracy: 0.1806\n",
      "Epoch 133/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.3064 - accuracy: 0.5212 - val_loss: 3.1152 - val_accuracy: 0.1725\n",
      "Epoch 134/150\n",
      "86/86 [==============================] - 5s 53ms/step - loss: 1.2933 - accuracy: 0.5360 - val_loss: 3.2247 - val_accuracy: 0.1849\n",
      "Epoch 135/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.2605 - accuracy: 0.5379 - val_loss: 3.2537 - val_accuracy: 0.1703\n",
      "Epoch 136/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.2520 - accuracy: 0.5401 - val_loss: 3.2481 - val_accuracy: 0.1703\n",
      "Epoch 137/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.2636 - accuracy: 0.5408 - val_loss: 3.3087 - val_accuracy: 0.1813\n",
      "Epoch 138/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.2564 - accuracy: 0.5521 - val_loss: 3.2036 - val_accuracy: 0.1879\n",
      "Epoch 139/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.2528 - accuracy: 0.5501 - val_loss: 3.2942 - val_accuracy: 0.1711\n",
      "Epoch 140/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.2227 - accuracy: 0.5534 - val_loss: 3.2460 - val_accuracy: 0.1681\n",
      "Epoch 141/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.2339 - accuracy: 0.5497 - val_loss: 3.3489 - val_accuracy: 0.1623\n",
      "Epoch 142/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.2308 - accuracy: 0.5452 - val_loss: 3.3717 - val_accuracy: 0.1652\n",
      "Epoch 143/150\n",
      "86/86 [==============================] - 5s 53ms/step - loss: 1.2087 - accuracy: 0.5594 - val_loss: 3.3818 - val_accuracy: 0.1630\n",
      "Epoch 144/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.1944 - accuracy: 0.5636 - val_loss: 3.4274 - val_accuracy: 0.1703\n",
      "Epoch 145/150\n",
      "86/86 [==============================] - 5s 53ms/step - loss: 1.2448 - accuracy: 0.5525 - val_loss: 3.4828 - val_accuracy: 0.1674\n",
      "Epoch 146/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.2308 - accuracy: 0.5561 - val_loss: 3.4509 - val_accuracy: 0.1842\n",
      "Epoch 147/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.2021 - accuracy: 0.5594 - val_loss: 3.5203 - val_accuracy: 0.1740\n",
      "Epoch 148/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.1836 - accuracy: 0.5708 - val_loss: 3.5640 - val_accuracy: 0.1615\n",
      "Epoch 149/150\n",
      "86/86 [==============================] - 5s 54ms/step - loss: 1.1540 - accuracy: 0.5761 - val_loss: 3.5396 - val_accuracy: 0.1703\n",
      "Epoch 150/150\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 1.1550 - accuracy: 0.5715 - val_loss: 3.6840 - val_accuracy: 0.1659\n",
      "72/72 [==============================] - 1s 10ms/step\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 3.1182 - accuracy: 0.2447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1181764602661133, 0.24472759664058685]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    n_outputs,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model_history=model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=150,\n",
    "    batch_size=64,\n",
    "#    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test, axis=1) # 배열에서 최댓값을 가지는 원소의 인덱스를 반환하는 함수\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589f0a1-c529-4c6c-b7b7-b6501c4678ea",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83ea44b9-59d0-44fe-9981-7d1eeb167f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "# 훈련 손실(training loss)과 검증 손실(validation loss) 추출\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "# 에포크(epoch) 범위 생성\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# 훈련 손실(training loss)과 검증 손실(validation loss) 시각화\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')  # 훈련 손실을 노란색(yellow)으로 플롯\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')  # 검증 손실을 빨간색(red)으로 플롯\n",
    "plt.title('Training and validation loss')  # 그래프 제목 설정\n",
    "plt.xlabel('Epochs')  # x축 레이블 설정\n",
    "plt.ylabel('Loss')  # y축 레이블 설정\n",
    "plt.legend()  # 범례(legend) 표시\n",
    "plt.show()  # 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "193a8e35-e4ae-4e3c-8fc0-b8c732c32d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc =model_history.history['accuracy']\n",
    "val_acc =model_history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1962e63-4f02-48fc-8d34-a89b7d3159ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------classification_report-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.30      0.28       118\n",
      "           1       0.26      0.25      0.26       124\n",
      "           2       0.27      0.28      0.27       119\n",
      "           3       0.18      0.15      0.17       118\n",
      "           4       0.23      0.23      0.23       126\n",
      "           5       0.29      0.18      0.22       130\n",
      "           6       0.30      0.30      0.30       130\n",
      "           7       0.27      0.16      0.20       126\n",
      "           8       0.29      0.25      0.27       120\n",
      "           9       0.19      0.18      0.19       127\n",
      "          10       0.28      0.35      0.31       113\n",
      "          11       0.23      0.23      0.23       122\n",
      "          12       0.27      0.27      0.27       127\n",
      "          13       0.29      0.24      0.26       112\n",
      "          14       0.11      0.09      0.10       113\n",
      "          15       0.25      0.35      0.29       116\n",
      "          16       0.23      0.33      0.27       118\n",
      "          17       0.21      0.17      0.19       111\n",
      "          18       0.21      0.37      0.27       106\n",
      "\n",
      "    accuracy                           0.24      2276\n",
      "   macro avg       0.24      0.25      0.24      2276\n",
      "weighted avg       0.25      0.24      0.24      2276\n",
      "\n",
      "\n",
      "------------------confusion_matrix--------------------\n",
      "[[35  4  4  2  6  4  7  4  4 10  6  6  6  2  2  2  3  4  7]\n",
      " [ 5 31  8  6  5  1  7  5  1  5  4  2  3  7  5  4  7  9  9]\n",
      " [ 9  5 33  5  4  6  6  1  4  5  4  5  3  3  4  7  3  5  7]\n",
      " [ 7  5  4 18  6  4  7  1  4  3  5  5  5  2  4 11  5  7 15]\n",
      " [ 9  8  2  4 29  5  6  2  3  3  7  4  5  4  2  7  9  6 11]\n",
      " [ 1  2  3  4 11 23  5  4  8  9  8  8  7  2  5  8 11  7  4]\n",
      " [ 1  3  7  5  3  8 39  5  5  3  6  7  6  4  5  6  6  2  9]\n",
      " [ 8  4  8  5 10  1  3 20  3  3  2  7 10  5  6  7  8  2 14]\n",
      " [ 5  7  3  7  5  2  5  2 30  7  7  4  7  3  5  4  9  1  7]\n",
      " [ 8  3  3  2  8  1  8  3  0 23 10  6  7  4  8  9  8  5 11]\n",
      " [ 4  3  8  2  5  0  3  2  3  6 39  1  5  3  8  9  4  5  3]\n",
      " [ 6  3  5  5  5  2  4  3  3 10  7 28  4  2  5  6 11  5  8]\n",
      " [11  7  7  3  5  4  4  4  8  3  4  8 34  3  2 10  6  2  2]\n",
      " [ 8  4  7  5  2  3  3  4  5  0  5  2  6 27 12  7  4  1  7]\n",
      " [ 4  5  5  7  9  4  2  1  7  9  6  9  0  9 10  9 10  3  4]\n",
      " [ 2  4  8  2  1  4  9  1  3  5  4  2  7  3  3 41  8  3  6]\n",
      " [ 2 11  2  5  4  1  2  2  5  7  5  7  6  2  2  5 39  3  8]\n",
      " [ 3  4  2  3  3  5  4  4  4  4  5  7  6  4  4  4 14 19 12]\n",
      " [ 5  4  2  8  4  0  5  5  3  3  3  5  0  3  1  6  7  3 39]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------classification_report-----------------\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(\"\\n------------------confusion_matrix--------------------\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
